---
title: "11 Area Data III"
output: html_notebook
---

#Introduction

NOTE: This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

In last previous practice/session, you learned about different ways to define _proximity_ for area data, about spatial weights matrices, and how spatial weights matrices could be used to calculate spatial moving averages. 

For this practice you will need the following:

* This R markdown notebook.
* A shape file called "Hamilton CMA CT"

This dataset includes the spatial information for the census tracts in the Hamilton Census Metropolitan Area (as polygons), and a host of demographic variables from the census of Canada, including population and languages.

#Learning objectives

In this practice, you will learn about:

1. Spatial moving averages and simulation. 
2. The concept of spatial autocorrelation.
3. Moran's I coefficient and Moran's scatterplot.
4. Hypothesis testing for spatial autocorrelation.

#Suggested reading

O'Sullivan D and Unwin D (2010) Geographic Information Analysis, 2nd Edition, Chapter 7. John Wiley & Sons: New Jersey.

#Preliminaries

As usual, it is good practice to clear the working space to make sure that you do not have extraneous items there when you begin your work. The command in R to clear the workspace is `rm` (for "remove"), followed by a list of items to be removed. To clear the workspace from _all_ objects, do the following:
```{r}
rm(list = ls())
```

Note that `ls()` lists all objects currently on the worspace.

Load the libraries you will use in this activity:
```{r}
library(tidyverse)
library(rgdal)
library(broom)
#library(plotly)
library(spdep)
library(reshape2)
library(gridExtra)
```

Read the data that you will use for this practice. This is an Esri shape file that will be saved as an object of class `SpatialPolygonDataFrame`. The function used to read Esri shape files is `rgdal::readOGR`. Setting `integer64` to "allow.loss" keeps the data as integers as opposed to changing to factors or strings:
```{r echo=FALSE}
Hamilton_CT <- readOGR(".", layer = "Hamilton CMA CT", integer64 = "allow.loss")
```

Clear the dataframe, retain only `ID`, `TRACT`, and `POP_DENSIT`:
```{r}
Hamilton_CT@data <- transmute(Hamilton_CT@data, ID = ID, TRACT = TRACT, POP_DENSIT = POP_DENSIT)
```

To use the plotting functions of `ggplot2`, the `SpatialPolygonDataFrame` needs to be "tidied" by means of the `tidy` function of the `broom` package:
```{r}
Hamilton_CT.t <- tidy(Hamilton_CT, region = "TRACT")
Hamilton_CT.t <- dplyr::rename(Hamilton_CT.t, TRACT = id)
```

Tidying the spatial dataframe strips it from the non-spatial information, but we can add all the data by means of the `left_join` function:
```{r}
Hamilton_CT.t <- left_join(Hamilton_CT.t, Hamilton_CT@data, by = "TRACT")
```

Now the tidy dataframe `Hamilton_DA.t` contains the spatial information and the data.

You can quickly verify the contents of the dataframe by means of `summary`:
```{r}
summary(Hamilton_CT.t)
```

# Spatial moving averages and simulation

Last practice/activity you learned about spatial weights matrices as a way to define proximity in the analysis of area data. You also used spatial moving averages to explore spatial patterns in area data.

Lets briefly revisit these notions. Here, you create a spatial weights matrix for Hamilton CMA census tracts:
```{r}
Hamilton_CT.nb <- poly2nb(pl = Hamilton_CT)
Hamilton_CT.w <- nb2listw(Hamilton_CT.nb)
```

The spatial moving averages are calculated as follows:
```{r}
POP_DENSIT.sma <- lag.listw(Hamilton_CT.w, Hamilton_CT$POP_DENSIT)
```

Let's append the spatial moving averages to our dataframes, in the `SpatialPolygonsDataFrame` and the tidied version of it both:
```{r}
Hamilton_CT$POP_DENSIT.sma <- POP_DENSIT.sma
Hamilton_CT.t <- left_join(Hamilton_CT.t, data.frame(TRACT = Hamilton_CT$TRACT, POP_DENSIT.sma))
```

The spatial moving average can be used in two ways to explore the spatial pattern of an area variable: as a smoother and by means of a scatterplot, combined with the original variable.

## Spatial moving average as a smoother

First, when mapped, it is essentially a smoothing technique, in that it reduces the amount of variability to make it easier to distinguish the overall pattern.

This can be illustrated with the help of a little simulation.

To simulate a random spatial variable, we can randomize the observations that we already have, reassigning them at random to areas in the system. This is accomplished as follows:
```{r}
POP_DENSITs1 <- sample(Hamilton_CT$POP_DENSIT)
```

Calculate the spatial moving average for this randomized variable:
```{r}
POP_DENSITs1.sma <- lag.listw(Hamilton_CT.w, POP_DENSITs1)
```

Once that you know how to randomize the variable, simulate a total of eight variables, and calculate their spatial moving averages:
```{r}
POP_DENSITs2 <- sample(Hamilton_CT$POP_DENSIT)
POP_DENSITs2.sma <- lag.listw(Hamilton_CT.w, POP_DENSITs2)
POP_DENSITs3 <- sample(Hamilton_CT$POP_DENSIT)
POP_DENSITs3.sma <- lag.listw(Hamilton_CT.w, POP_DENSITs3)
POP_DENSITs4 <- sample(Hamilton_CT$POP_DENSIT)
POP_DENSITs4.sma <- lag.listw(Hamilton_CT.w, POP_DENSITs4)
POP_DENSITs5 <- sample(Hamilton_CT$POP_DENSIT)
POP_DENSITs5.sma <- lag.listw(Hamilton_CT.w, POP_DENSITs5)
POP_DENSITs6 <- sample(Hamilton_CT$POP_DENSIT)
POP_DENSITs6.sma <- lag.listw(Hamilton_CT.w, POP_DENSITs6)
POP_DENSITs7 <- sample(Hamilton_CT$POP_DENSIT)
POP_DENSITs7.sma <- lag.listw(Hamilton_CT.w, POP_DENSITs7)
POP_DENSITs8 <- sample(Hamilton_CT$POP_DENSIT)
POP_DENSITs8.sma <- lag.listw(Hamilton_CT.w, POP_DENSITs8)
```

Now, append the spatial moving averages to the dataframes:
```{r}
Hamilton_CT$POP_DENSITs1 <- POP_DENSITs1
Hamilton_CT$POP_DENSITs1.sma <- POP_DENSITs1.sma
Hamilton_CT$POP_DENSITs2 <- POP_DENSITs2
Hamilton_CT$POP_DENSITs2.sma <- POP_DENSITs2.sma
Hamilton_CT$POP_DENSITs3 <- POP_DENSITs3
Hamilton_CT$POP_DENSITs3.sma <- POP_DENSITs3.sma
Hamilton_CT$POP_DENSITs4 <- POP_DENSITs4
Hamilton_CT$POP_DENSITs4.sma <- POP_DENSITs4.sma
Hamilton_CT$POP_DENSITs5 <- POP_DENSITs5
Hamilton_CT$POP_DENSITs5.sma <- POP_DENSITs5.sma
Hamilton_CT$POP_DENSITs6 <- POP_DENSITs6
Hamilton_CT$POP_DENSITs6.sma <- POP_DENSITs6.sma
Hamilton_CT$POP_DENSITs7 <- POP_DENSITs7
Hamilton_CT$POP_DENSITs7.sma <- POP_DENSITs7.sma
Hamilton_CT$POP_DENSITs8 <- POP_DENSITs8
Hamilton_CT$POP_DENSITs8.sma <- POP_DENSITs8.sma
Hamilton_CT.t <- left_join(Hamilton_CT.t, 
                           data.frame(TRACT = Hamilton_CT$TRACT, 
                                      POP_DENSITs1, POP_DENSITs1.sma,
                                      POP_DENSITs2, POP_DENSITs2.sma,
                                      POP_DENSITs3, POP_DENSITs3.sma,
                                      POP_DENSITs4, POP_DENSITs4.sma,
                                      POP_DENSITs5, POP_DENSITs5.sma,
                                      POP_DENSITs6, POP_DENSITs6.sma,
                                      POP_DENSITs7, POP_DENSITs7.sma,
                                      POP_DENSITs8, POP_DENSITs8.sma))
```

Now, create choropleth maps of the empirical variable and the eight simulated variables (don't worry too much here about the mechanics of creating and plotting the maps). First tidy the data for convenience:
```{r}
Hamilton_CT.t <- Hamilton_CT.t %>%
  melt(id.vars = c("long", "lat", "order", "hole", "piece", "group", "TRACT", "ID", "POP_DENSIT", "POP_DENSITs1", "POP_DENSITs2", "POP_DENSITs3", "POP_DENSITs4", "POP_DENSITs5", "POP_DENSITs6", "POP_DENSITs7", "POP_DENSITs8")) %>%
  rename(Map.SMA = variable, SMA = value) 
```

And then plot using `facet_wrap`:
```{r}
ggplot(data = Hamilton_CT.t, 
       aes(x = long, y = lat, group = group,
           fill = cut_number(SMA, 5))) +   
  geom_polygon() +  
  theme(axis.text.x = element_blank(), axis.text.y = element_blank()) +
  scale_fill_brewer(palette = "YlOrRd") + 
  coord_equal() + 
  facet_wrap(~ as.numeric(Map.SMA), ncol = 3, nrow = 3) + 
  labs(fill = "Pop Den SMA")
```

The empirical variable is map number 1 above. Maps 2 through 9 are simulated variables. Would you say the map of the empirical variable is fairly different from the map of the simulated variables? What are the key differences?

Perhaps similar insights could be derived from randomizing the original population density variable, instead of the spatial moving average. An additional advantage of the spatial moving average is its use in the development of scatterplots.

## Spatial moving average scatterplots

Let us explore the use of spatial moving average scatterplots (again, do not worry too much about the mechanics of how create these plots).

Reorganize the data for convenience:
```{r}
df_scatterplots <-  rbind(data.frame(select(Hamilton_CT@data, 
                                            Density = POP_DENSIT, 
                                            SMA = POP_DENSIT.sma), 
                                     Type = "Empirical"),
                          data.frame(select(Hamilton_CT@data, 
                                            Density = POP_DENSITs1,
                                            SMA = POP_DENSITs1.sma), 
                                     Type = "Sim 1"),
                          data.frame(select(Hamilton_CT@data, 
                                            Density = POP_DENSITs2, 
                                            SMA = POP_DENSITs2.sma), 
                                     Type = "Sim 2"),
                          data.frame(select(Hamilton_CT@data, 
                                            Density = POP_DENSITs3,
                                            SMA = POP_DENSITs3.sma), 
                                     Type = "Sim 3"),
                          data.frame(select(Hamilton_CT@data, 
                                            Density = POP_DENSITs4,
                                            SMA = POP_DENSITs4.sma), 
                                     Type = "Sim 4"),
                          data.frame(select(Hamilton_CT@data, 
                                            Density = POP_DENSITs5,
                                            SMA = POP_DENSITs5.sma), 
                                     Type = "Sim 5"),
                          data.frame(select(Hamilton_CT@data, 
                                            Density = POP_DENSITs6,
                                            SMA = POP_DENSITs6.sma), 
                                     Type = "Sim 6"),
                          data.frame(select(Hamilton_CT@data, 
                                            Density = POP_DENSITs7, 
                                            SMA = POP_DENSITs7.sma), 
                                     Type = "Sim 7"),
                          data.frame(select(Hamilton_CT@data, 
                                            Density = POP_DENSITs8,
                                            SMA = POP_DENSITs8.sma), 
                                     Type = "Sim 8"))
```

Create the scatterplot of the empirical population density and its spatial moving average, and the scatterplots of the simulated variables and their spatial moving averages  for comparison (the plots include the 45 degree line):
```{r}
ggplot(data = df_scatterplots, aes(x = Density, y = SMA, color = Type)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  coord_equal() +
  facet_wrap(~ Type, ncol = 3, nrow = 3)
```

What difference do you see between the empirical and simulated variables in these scatterplots?

Fitting a line to the scatterplots (i.e., adding a regression line), makes the difference between the empirical and simulated variables easier to appreciate. This line would take the following form, with $\beta$ as the slope of the line, and $\alpha$ the intercept:
$$
\overline{x_i} =\alpha + \beta x_i
$$

Plot the scatterplots with fitted lines:
```{r}
ggplot(data = df_scatterplots, aes(x = Density, y = SMA, color = Type)) +
  geom_point(alpha = 0.1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  geom_smooth(method = "lm") +
  coord_equal() +
  facet_wrap(~ Type, ncol = 3, nrow = 3)
```

You will notice that the slope of the line tends to be flat in the simulated variables; this is to be expected, since these variables are spatially random: _the values of the variable at $i$ are independent of the values of their local means!_. In other words, the possibility of a non-random spatial pattern is low.

The empirical variable, on the other hand, has a slope that is much closer to the 45 degree line. This indicates that the values of the variable at $i$ are not independent of their local means: in other words, $x_i$ is correlated with $\overline{x_i}$, and the possibility of a non-random pattern is high. This phenomenon is called _spatial autocorrelation_.

# Spatial autocorrelation and Moran's I coefficient

As seen above, the spatial moving average can provide evidence of the phenomenon of spatial autocorrelation, that is, when a variable displays spatial patterns whereby values at $i$ are not independent of the values of the variable in their neighborhood.

A convenient modification to the concept of the spatial moving average is as follows. Instead of using the variable $x$ for the calculation of the spatial moving average, we first center it on the global mean:
$$
z_i = x_i - \overline{x}
$$

In this way, the values of $z_i$ are given in _deviations from the mean_. By forcing the variable to be centered on the mean, the slope of the fit line is forced to pass through the origin.

Calculate the mean-centered version of POP_DENSIT, and then its spatial moving average:
```{r}
df_mean_center_scatterplot <- 
  transmute(Hamilton_CT@data, 
            Density_z = POP_DENSIT - mean(POP_DENSIT), 
            SMA_z = lag.listw(Hamilton_CT.w, Density_z))
```

Compare the following two plots. You will see that they are identical, but in the mean-centered one the origin of the axes coincides with the means of $x$ and the spatial moving average:
```{r}
sc1 <- ggplot(data = subset(df_scatterplots, Type == "Empirical"), 
       aes(x = Density, y = SMA)) +
  geom_point(alpha = 0.1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  geom_smooth(method = "lm") +
  ggtitle("Population Density") +
  coord_equal()
sc2 <- ggplot(data = df_mean_center_scatterplot, 
       aes(x = Density_z, y = SMA_z)) +
  geom_point(alpha = 0.1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  geom_smooth(method = "lm", formula = y ~ x-1) +
  ggtitle("Mean-Centered Population Density") +
  coord_equal()
grid.arrange(sc1, sc2, ncol = 1)
```

Notice what happens when the variable $z_i$ multiplies its spatial moving average:
$$
z_i\overline{z_i} = z_i\sum_{j=1}^n{w_{ij}^{st}z_j}
$$

When $z_i$ is above its mean, it is a positive value and negative otherwise. Likewise, when $\overline{z_i}$ is above its mean, it is a positive value, and negative otherwise.

There are four posibilities with respect to the combinations of (relatively) high and low values.

1. Quadrant 1 (high & high):

If $z_i$ is above the mean, it is a relatively high value in the distribution (signed positive). If its neighbors are also relatively high values, the spatial moving average will be above the mean, and also signed positive. Their product will be positive (positive times positive equals positive).

2. Quadrant 2 (low & high): 

If $z_i$ is below the mean, it is a relatively low value in the distribution (signed negative). If its neighbors in contrast are relatively high values, the spatial moving average will be above the mean, and signed positive. Their product will be negative (negative times positive equals negative).

3. Quadrant 3 (low & low): 

If $z_i$ is below the mean, it is a relatively low value in the distribution (signed negative). If its neighbors are also relatively low values, the spatial moving average will be below the mean, and also signed negative. Their product will be positive (negative times negative equals positive).

4. Quadrant 4: 

If $z_i$ is above the mean, it is a relatively high value in the distribution (signed positive). If its neighbors are relatively low values, the spatial moving average will be below the mean, and signed negative. Their product will be negative (positive times negative equals negative).

These four quadrants are shown in the following plot:
```{r}
ggplot(data = df_mean_center_scatterplot, 
       aes(x = Density_z, y = SMA_z)) +
  geom_point(color = "gray") +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 0) +
  annotate("text", label = "Q1: Positive", x= 2000, y = 2500) +
  annotate("text", label = "Q4: Negative", x= 2000, y = -2500) +
  annotate("text", label = "Q2: Negative", x= -2000, y = 2500) +
  annotate("text", label = "Q3: Positive", x= -2000, y = -2500) +
  coord_equal()

```

Lets say that we add all such products:
$$
\sum_{i=1}^n{z_i\overline{z_i}} = \sum_{i=1}^n{z_i\sum_{j=1}^n{w_{ij}^{st}z_j}}
$$

The more such products are positive, meaning more dots in Quadrants 1 and 3 in the scatterplot, the larger (and positive) the total sum will be. Likewise, as more such products are negative, meaning more dots in Quadrants 2 and 4, the larger (but negative!) the total sum will be. 

Either case would be indicative of a pattern. 

If the sum is positive, this would suggest that high & high values tend to be together, while low & low values also tend to be together.

In contrast, if the sum is negative, this would suggest that high values tend to be surrounded by low values, and viceversa.

#Moran's I and Moran's scatterplot

Based on the discussion above, lets define the following coefficient, called _Moran's I_:
$$
I = \frac{\sum_{i=1}^n{z_i\sum_{j=1}^n{w_{ij}^{st}z_j}}}{\sum_{i=1}^{n}{z_i^2}}
$$

The numerator in this expression is the sum of the products described above. The denominator is the variance of variable $x_i$, and is used here to scale Moran's I so that it is contained roughly in the interval $(-1, 1)$ (the exact bounds depend on the characteristics of the zoning system).

Moran's I is a coefficient of _spatial autocorrelation_.

We can calculate Moran's I as follows (notice how it is the sum of the products of $z$ by its spatial moving average, divided by the variance):
```{r}
sum(df_mean_center_scatterplot$Density_z * df_mean_center_scatterplot$SMA_z) / sum(df_mean_center_scatterplot$Density_z^2)
```

Since the value is positive, and relatively high, this would suggest a non-random spatial pattern of similar values (i.e., high & high and low & low).

Moran's I is implemented in R in the `spdep` package, which makes its calculation easy, since you do not have to go manually through the process of calculating the spatial moving averages, etc.

The function `moran` requires as input arguments a variable, a set of spatial weights, the number of zones ($n$), and the total sum of all weights (termed $S_0$) - which in the case of row-standardized spatial weights is equal to the number of zones. Therefore:
```{r}
mc <- moran(Hamilton_CT$POP_DENSIT, Hamilton_CT.w, n = 188, S0 =  188)
mc$I
```

You can verify that this matches the value you calculated above. The kind of scatterplots that we used above (called _Moran's scatterplots_) can also be created easily by means of the `moran.plot` function:
```{r}
mp <- moran.plot(Hamilton_CT$POP_DENSIT, Hamilton_CT.w)
```

# Hypothesis testing for spatial autocorrelation

As usual, we need some criterion to decide whether the pattern is random.

Moran's I can be used to develop a test of hypothesis. The expected value of Moran's I under the null hypothesis of spatial independence and its variance have been derived.

A test for autocorrelation based on Moran's I is implemented in the `spdep` package:
```{r}
moran.test(Hamilton_CT$POP_DENSIT, Hamilton_CT.w)
```

The null hypothesis is of spatial independence. The p-value is interpreted as the probability of making a mistake by rejecting the null hypothesis. In the present case, the p-value is such a small number that we can reject the null hypothesis with a high degree of confidence.

Moran's I and Moran's scatterplots are amongst the most widely used tools in the analysis of spatial area data.

This concludes Practice 11.