Area Data VI
========================================================
author: Megan Coad and Alexis Polidoro
date: 
autosize: true


Key Points
========================================================

- Understand implications of incorrect functional form 
- 


Incorrect Functional Form
========================================================

```{r, include=FALSE}
rm(list = ls())
library(tidyverse)
library(sf)
#library(broom)
library(spdep)
#library(reshape2)
library(plotly)
library(knitr)
library(kableExtra)
library(spgwr)
library(geog4ga3)
data("HamiltonDAs")
```
 - An incorrect functional form can lead to residual spatial autocorrelation
 - To illustrate this we can simulate a spatial process
 
$$
z = f(x,y) = exp(\beta_0)exp(\beta_1x)exp(\beta_2y) + \epsilon_i
$$

- this is a non-linear spatial process


Incorrect Functional Form Contd. 
========================================================
```{r, include=FALSE}
set.seed(10)
b0 = 1
b1 = 2
b2 = 4
uv_coords <- st_coordinates(st_centroid(HamiltonDAs))
HamiltonDAs <- mutate(HamiltonDAs,
                            u = (uv_coords[,1] - min(uv_coords[,1]))/100000,
                            v = (uv_coords[,2] - min(uv_coords[,2]))/100000,
                            z = exp(b0) * exp(b1 * u) * exp(b2 * v) +
                              rnorm(n = 297, mean = 0, sd = 1))
```
-  Suppose that we estimate the model as a linear regression that does not correctly capture the non-linearity  

```{r, echo=FALSE}
model1 <- lm(formula = z ~ u + v, data = HamiltonDAs) 
summary(model1)
```


Incorrect Functional Form Contd. 
========================================================
```{r, include=FALSE}
HamiltonDAs$model1.e <- model1$residuals
```


- the model gives the impression of a very good fit: all coefficients are significant, and the coefficient of multiple determination $R^2$ is moderately high.

- it is important to examine the residuals to verify that they are independent

- A map of the residuals can help examine their spatial pattern

***

![An Image](Area_Data_VI_Figure_1.JPG)


Incorrect Functional Form Contd.
========================================================
- To test the residuals for spatial autocorrelation we first create a set of spatial weights and calculate Moran's I
```{r, echo=FALSE}
HamiltonDAs.w <- nb2listw(poly2nb(as(HamiltonDAs, "Spatial")))
```

```{r, echo=FALSE}
moran.test(HamiltonDAs$model1.e, HamiltonDAs.w)
```

- The test does not allow us to reject the null hypothesis of spatial independence
- despite the apparent goodness of fit of the model, more analysis needs to be done

Incorrect Functional Form Contd. 
========================================================

- Lets now use a variable transformation to approximate the underlying non-linear process:
```{r, include=FALSE}
model2 <- lm(formula = log(z) ~ u + v, data = HamiltonDAs)
summary(model2)
```

- This model does not necessarily have a better goodness of fit but when we test for spatial autocorrelation you can see that the model is better at capturing underlying processes 

```{r, echo=FALSE}
HamiltonDAs$model2.e <- model2$residuals
moran.test(HamiltonDAs$model2.e, HamiltonDAs.w)
```


Omitted Variables
========================================================
```{r, include=FALSE}
model3 <- lm(formula = log(z) ~ u, data = HamiltonDAs)
summary(model3)

HamiltonDAs$model3.e <- model3$residuals
```
- Using the same example, suppose now that the functional form of the model is correctly specified, but a relevant variable is missing
- We can plot a map of the residuals to examine their spatial pattern 
- the visual inspection makes it clear that there is an issue with spatially autocorrelated residuals
- the model with the full set of relevant variables resolves this problem

***

![An Image](Area_Data_VI_Figure_2.JPG)



Trend Surface Analysis
========================================================

- generates relatively flexible surfaces
- This approach consists of using the coordinates as covariates, and transforming them into polynomials of different orders

- Higher order polynomials are possible however the higher the order of the polynomial, the more flexible the surface, which may lead to issues

***

![An Image](Area_Data_VI_Figure_3.JPG)


Multicollinearity
========================================================
- When two variables are highly collinear, the model has difficulties discriminating their relative contribution to the model
- This is manifested by inflated standard errors that may depress the significance of the coefficients, and occasionally by sign reversals


Overfitting
========================================================
- when a model fits too well the observations used for callibration it may fail to fit new information well
- We can compute the _root mean square_  for multiple models to tell us the expected size of error when making a predition given a model (and to test for overfitting)


Edge effects
========================================================
- Another consequence of overfitting, is that the resulting functions tend to display extreme behavior when taken outside of their estimation range, where the largest polynomial terms tend to dominate. 

![An Image](Area_Data_VI_Figure_4.JPG)

Expansion Method
========================================================
- suppose that there is the following initial model of proportion of donors in a population, with two variables of substantive interest:
$$
d_i = \beta_i(u_i,v_i) + \beta_1(u_i,v_i)I_i + \beta_3(u_i,v_i)Ed_i + \epsilon_i
$$
- the coefficients in this model are allowed to adapt by location

- it is not possible to estimate one coefficient per location. In this case, there are $n\times k$ coefficients, which exceeds the size of the sample ($n$). It is not possible to retrieve more information from the sample than $n$ parameters (incidental parameter problem.)

- A  solution is to specify a function for the coefficients
$$
\begin{array}{l}
\beta_0(u_i, v_i) = \beta_{01} +\beta_{02}u_i + \beta_{03}v_i\\
\beta_1(u_i, v_i) = \beta_{11} +\beta_{12}u_i + \beta_{13}v_i\\
\beta_2(u_i, v_i) = \beta_{21} +\beta_{22}u_i + \beta_{23}v_i
\end{array}
$$

Expansion Method Contd. 
========================================================

- By specifying the coefficients as a function of the coordinates, we allow them to vary by location.

- if we substitute these coefficients in the intial model, we arrive at a final expanded model:
$$
d_i = \beta_{01} +\beta_{02}u_i + \beta_{03}v_i + \beta_{11}I_i +\beta_{12}u_iI_i + \beta_{13}v_iI_i + \beta_{21}Ed_i +\beta_{22}u_iEd_i + \beta_{23}v_iEd_i + \epsilon_i
$$

- This model has now nine coefficients, instead of $n\times 3$, and can be estimated as usual



Geographically Weighted Regression
========================================================
- the functions in this model are left unspecified
- The spatial variation of the coefficients results from an estimation strategy that takes subsamples of the data in a systematic way
- uses a moving window that visits a focal point and estimates a weighted least squares model at that location
- The results of the regression are conventionally applied to the focal point, in such a way that not only the coefficients are localized, but also every other regression diagnostic

Geographically Weighted Regression Contd. 
========================================================

-  selecting the kernel bandwidth is important 
- If the window is too large the local models tend towards the global model and if the window is too small, the model tends to overfit
- Since estimation requires the selection of a kernel bandwidth, and a kernel bandwidth requires the estimation of many times leave-one-out regressions, GWR can be computationally quite demanding, especially for large datasets.

***

![An Image](Area_Data_VI_Figure_5.JPG)

Spatial Error Model
========================================================
- A model that can be used to take direct remedial action with respect to residual spatial autocorrelation

- This model is specified as follows:
$$
y_i = \beta_0 + \sum_{j=1}^k{\beta_kx_{ij}} + \epsilon_i
$$

- it is no longer assumed that the residuals $\epsilon$ are independent, but instead display map pattern, in the shape of a moving average:
$$
\epsilon_i = \lambda\sum_{i=1}^n{w_{ij}^{st}\epsilon_i} + \mu_i
$$


























